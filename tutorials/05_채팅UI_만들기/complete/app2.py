import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from dotenv import load_dotenv
import os
from datetime import datetime
import uuid

load_dotenv()

st.set_page_config(page_title="LangChain Chat", page_icon="ğŸ’¬", layout="wide")

MODELS = {
    "gpt-4.1-nano": "gpt-4.1-nano-2025-04-14",
    "gpt-4.1-mini": "gpt-4.1-mini-2025-04-14",
    "gpt-5-mini": "gpt-5-mini-2025-08-07",
    "gpt-5-nano": "gpt-5-nano-2025-08-07"
}

if "conversations" not in st.session_state:
    first_id = str(uuid.uuid4())
    st.session_state.conversations = {
        first_id: {
            "id": first_id,
            "title": "ìƒˆ ëŒ€í™”",
            "messages": [],
            "created_at": datetime.now()
        }
    }
    st.session_state.active_conversation_id = first_id

if "selected_model" not in st.session_state:
    st.session_state.selected_model = "gpt-4.1-mini"

if "llm" not in st.session_state:
    st.session_state.llm = ChatOpenAI(
        model=MODELS[st.session_state.selected_model],
        temperature=0.7,
        streaming=True,
        api_key=os.getenv("OPENAI_API_KEY")
    )

def create_new_conversation():
    new_id = str(uuid.uuid4())
    st.session_state.conversations[new_id] = {
        "id": new_id,
        "title": "ìƒˆ ëŒ€í™”",
        "messages": [],
        "created_at": datetime.now()
    }
    st.session_state.active_conversation_id = new_id

def get_conversation_title(messages):
    if not messages:
        return "ìƒˆ ëŒ€í™”"
    first_user_msg = next((msg.content for msg in messages if isinstance(msg, HumanMessage)), None)
    if first_user_msg:
        return first_user_msg[:30] + "..." if len(first_user_msg) > 30 else first_user_msg
    return "ìƒˆ ëŒ€í™”"

def delete_conversation(conv_id):
    if len(st.session_state.conversations) > 1:
        del st.session_state.conversations[conv_id]
        if st.session_state.active_conversation_id == conv_id:
            st.session_state.active_conversation_id = list(st.session_state.conversations.keys())[0]

current_conv = st.session_state.conversations[st.session_state.active_conversation_id]

col1, col2 = st.columns([6, 1])
with col1:
    st.title("ğŸ’¬ LangChain Chat")
with col2:
    if st.button("â• ìƒˆ ëŒ€í™”", use_container_width=True):
        create_new_conversation()
        st.rerun()

with st.sidebar:
    st.header("ì„¤ì •")
    
    model_choice = st.selectbox(
        "ëª¨ë¸ ì„ íƒ",
        options=list(MODELS.keys()),
        index=list(MODELS.keys()).index(st.session_state.selected_model),
        key="model_selectbox"
    )
    
    if model_choice != st.session_state.selected_model:
        st.session_state.selected_model = model_choice
        st.session_state.llm = ChatOpenAI(
            model=MODELS[model_choice],
            temperature=0.7,
            streaming=True,
            api_key=os.getenv("OPENAI_API_KEY")
        )
        st.success(f"ëª¨ë¸ì´ {model_choice}ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    st.divider()
    
    st.subheader("ëŒ€í™” ì„¸ì…˜")
    
    sorted_convs = sorted(
        st.session_state.conversations.values(),
        key=lambda x: x["created_at"],
        reverse=True
    )
    
    for conv in sorted_convs:
        is_active = conv["id"] == st.session_state.active_conversation_id
        
        col1, col2 = st.columns([4, 1])
        
        with col1:
            button_type = "primary" if is_active else "secondary"
            title = get_conversation_title(conv["messages"])
            if st.button(
                f"{'ğŸ“Œ' if is_active else 'ğŸ’¬'} {title}",
                key=f"conv_{conv['id']}",
                use_container_width=True,
                type=button_type
            ):
                st.session_state.active_conversation_id = conv["id"]
                st.rerun()
        
        with col2:
            if len(st.session_state.conversations) > 1:
                if st.button("ğŸ—‘ï¸", key=f"del_{conv['id']}", use_container_width=True):
                    delete_conversation(conv["id"])
                    st.rerun()
    
    st.divider()
    
    st.subheader("í˜„ì¬ ëŒ€í™” ì •ë³´")
    if current_conv["messages"]:
        total_messages = len([msg for msg in current_conv["messages"] if isinstance(msg, (HumanMessage, AIMessage))])
        st.write(f"ì´ ë©”ì‹œì§€ ìˆ˜: {total_messages}")
        st.write(f"ìƒì„± ì‹œê°„: {current_conv['created_at'].strftime('%Y-%m-%d %H:%M')}")
        
        with st.expander("ì „ì²´ íˆìŠ¤í† ë¦¬ ë³´ê¸°"):
            for idx, msg in enumerate(current_conv["messages"]):
                if isinstance(msg, HumanMessage):
                    st.markdown(f"**ì‚¬ìš©ì [{idx+1}]:** {msg.content}")
                elif isinstance(msg, AIMessage):
                    st.markdown(f"**AI [{idx+1}]:** {msg.content}")
    else:
        st.write("ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

for message in current_conv["messages"]:
    if isinstance(message, HumanMessage):
        with st.chat_message("user"):
            st.markdown(message.content)
    elif isinstance(message, AIMessage):
        with st.chat_message("assistant"):
            st.markdown(message.content)

if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    current_conv["messages"].append(HumanMessage(content=prompt))
    
    with st.chat_message("user"):
        st.markdown(prompt)
    
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        for chunk in st.session_state.llm.stream(current_conv["messages"]):
            full_response += chunk.content
            message_placeholder.markdown(full_response + "â–Œ")
        
        message_placeholder.markdown(full_response)
    
    current_conv["messages"].append(AIMessage(content=full_response))
    st.rerun()
