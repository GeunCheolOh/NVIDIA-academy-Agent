import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_community.tools.tavily_search import TavilySearchResults
from ddgs import DDGS
from dotenv import load_dotenv
import os
from datetime import datetime
import uuid

load_dotenv()

st.set_page_config(page_title="LangChain Chat", page_icon="ğŸ’¬", layout="wide")

MODELS = {
    "gpt-4.1-nano": "gpt-4.1-nano-2025-04-14",
    "gpt-4.1-mini": "gpt-4.1-mini-2025-04-14",
    "gpt-5-mini": "gpt-5-mini-2025-08-07",
    "gpt-5-nano": "gpt-5-nano-2025-08-07"
}

if "conversations" not in st.session_state:
    first_id = str(uuid.uuid4())
    st.session_state.conversations = {
        first_id: {
            "id": first_id,
            "title": "ìƒˆ ëŒ€í™”",
            "messages": [],
            "search_results": {},
            "system_prompt": "",
            "created_at": datetime.now()
        }
    }
    st.session_state.active_conversation_id = first_id

if "selected_model" not in st.session_state:
    st.session_state.selected_model = "gpt-4.1-mini"

if "search_engine" not in st.session_state:
    st.session_state.search_engine = None

if "llm" not in st.session_state:
    st.session_state.llm = ChatOpenAI(
        model=MODELS[st.session_state.selected_model],
        temperature=0.7,
        streaming=True,
        api_key=os.getenv("OPENAI_API_KEY")
    )

def create_new_conversation():
    new_id = str(uuid.uuid4())
    st.session_state.conversations[new_id] = {
        "id": new_id,
        "title": "ìƒˆ ëŒ€í™”",
        "messages": [],
        "search_results": {},
        "system_prompt": "",
        "created_at": datetime.now()
    }
    st.session_state.active_conversation_id = new_id

def get_conversation_title(messages):
    if not messages:
        return "ìƒˆ ëŒ€í™”"
    first_user_msg = next((msg.content for msg in messages if isinstance(msg, HumanMessage)), None)
    if first_user_msg:
        return first_user_msg[:30] + "..." if len(first_user_msg) > 30 else first_user_msg
    return "ìƒˆ ëŒ€í™”"

def delete_conversation(conv_id):
    if len(st.session_state.conversations) > 1:
        del st.session_state.conversations[conv_id]
        if st.session_state.active_conversation_id == conv_id:
            st.session_state.active_conversation_id = list(st.session_state.conversations.keys())[0]

def search_tavily(query):
    try:
        api_key = os.getenv("TAVILY_API_KEY")
        if not api_key:
            return None, "âŒ Tavily API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— TAVILY_API_KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”."
        
        search_tool = TavilySearchResults(
            max_results=5,
            api_key=api_key
        )
        results = search_tool.invoke(query)
        
        formatted_results = "### ğŸ” Tavily ê²€ìƒ‰ ê²°ê³¼:\n\n"
        for i, result in enumerate(results, 1):
            formatted_results += f"**{i}. {result.get('title', 'No title')}**\n"
            formatted_results += f"{result.get('content', result.get('snippet', 'No content'))}\n"
            formatted_results += f"ğŸ”— {result.get('url', '')}\n\n"
        
        return formatted_results, None
    except Exception as e:
        return None, f"âŒ Tavily ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"

def search_duckduckgo(query):
    try:
        ddgs = DDGS()
        results = list(ddgs.text(query, max_results=5))
        
        formatted_results = "### ğŸ” DuckDuckGo ê²€ìƒ‰ ê²°ê³¼:\n\n"
        
        if results:
            for i, result in enumerate(results, 1):
                formatted_results += f"**{i}. {result.get('title', 'No title')}**\n"
                formatted_results += f"{result.get('body', 'No description')}\n"
                formatted_results += f"ğŸ”— {result.get('href', '')}\n\n"
        else:
            formatted_results += "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
        
        return formatted_results, None
    except Exception as e:
        return None, f"âŒ DuckDuckGo ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"

current_conv = st.session_state.conversations[st.session_state.active_conversation_id]

col1, col2 = st.columns([6, 1])
with col1:
    st.title("ğŸ’¬ LangChain Chat")
with col2:
    if st.button("â• ìƒˆ ëŒ€í™”", use_container_width=True):
        create_new_conversation()
        st.rerun()

with st.sidebar:
    st.header("ì„¤ì •")
    
    model_choice = st.selectbox(
        "ëª¨ë¸ ì„ íƒ",
        options=list(MODELS.keys()),
        index=list(MODELS.keys()).index(st.session_state.selected_model),
        key="model_selectbox"
    )
    
    if model_choice != st.session_state.selected_model:
        st.session_state.selected_model = model_choice
        st.session_state.llm = ChatOpenAI(
            model=MODELS[model_choice],
            temperature=0.7,
            streaming=True,
            api_key=os.getenv("OPENAI_API_KEY")
        )
        st.success(f"ëª¨ë¸ì´ {model_choice}ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    st.divider()
    
    st.subheader("ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸")
    
    if "system_prompt" not in current_conv:
        current_conv["system_prompt"] = ""
    
    system_prompt = st.text_area(
        "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •",
        value=current_conv.get("system_prompt", ""),
        height=150,
        placeholder="ì˜ˆ: ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. í•­ìƒ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.",
        help="AIì˜ ì—­í• ê³¼ ë‹µë³€ ìŠ¤íƒ€ì¼ì„ ì •ì˜í•©ë‹ˆë‹¤. ë¹„ì›Œë‘ë©´ ê¸°ë³¸ ë™ì‘ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
    )
    
    if system_prompt != current_conv.get("system_prompt", ""):
        current_conv["system_prompt"] = system_prompt
        if system_prompt:
            st.success("ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            st.info("ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    if current_conv.get("system_prompt"):
        st.caption(f"âœ“ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í™œì„±í™” ({len(current_conv['system_prompt'])}ì)")
    
    st.divider()
    
    st.subheader("ëŒ€í™” ì„¸ì…˜")
    
    sorted_convs = sorted(
        st.session_state.conversations.values(),
        key=lambda x: x["created_at"],
        reverse=True
    )
    
    for conv in sorted_convs:
        is_active = conv["id"] == st.session_state.active_conversation_id
        
        col1, col2 = st.columns([4, 1])
        
        with col1:
            button_type = "primary" if is_active else "secondary"
            title = get_conversation_title(conv["messages"])
            if st.button(
                f"{'ğŸ“Œ' if is_active else 'ğŸ’¬'} {title}",
                key=f"conv_{conv['id']}",
                use_container_width=True,
                type=button_type
            ):
                st.session_state.active_conversation_id = conv["id"]
                st.rerun()
        
        with col2:
            if len(st.session_state.conversations) > 1:
                if st.button("ğŸ—‘ï¸", key=f"del_{conv['id']}", use_container_width=True):
                    delete_conversation(conv["id"])
                    st.rerun()
    
    st.divider()
    
    st.subheader("í˜„ì¬ ëŒ€í™” ì •ë³´")
    if current_conv["messages"]:
        total_messages = len([msg for msg in current_conv["messages"] if isinstance(msg, (HumanMessage, AIMessage))])
        st.write(f"ì´ ë©”ì‹œì§€ ìˆ˜: {total_messages}")
        st.write(f"ìƒì„± ì‹œê°„: {current_conv['created_at'].strftime('%Y-%m-%d %H:%M')}")
        
        with st.expander("ì „ì²´ íˆìŠ¤í† ë¦¬ ë³´ê¸°"):
            for idx, msg in enumerate(current_conv["messages"]):
                if isinstance(msg, HumanMessage):
                    st.markdown(f"**ì‚¬ìš©ì [{idx+1}]:** {msg.content}")
                elif isinstance(msg, AIMessage):
                    st.markdown(f"**AI [{idx+1}]:** {msg.content}")
    else:
        st.write("ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

for idx, message in enumerate(current_conv["messages"]):
    if isinstance(message, HumanMessage):
        with st.chat_message("user"):
            st.markdown(message.content)
        if idx in current_conv.get("search_results", {}):
            with st.expander("ğŸ” ê²€ìƒ‰ ê²°ê³¼ ë³´ê¸°", expanded=False):
                st.markdown(current_conv["search_results"][idx])
    elif isinstance(message, AIMessage):
        with st.chat_message("assistant"):
            st.markdown(message.content)

col1, col2, col3 = st.columns([1, 1, 6])
with col1:
    tavily_enabled = st.button("ğŸŒ Tavily", use_container_width=True, 
                               type="primary" if st.session_state.search_engine == "tavily" else "secondary")
    if tavily_enabled:
        st.session_state.search_engine = "tavily" if st.session_state.search_engine != "tavily" else None

with col2:
    duckduckgo_enabled = st.button("ğŸ¦† DuckDuckGo", use_container_width=True,
                              type="primary" if st.session_state.search_engine == "duckduckgo" else "secondary")
    if duckduckgo_enabled:
        st.session_state.search_engine = "duckduckgo" if st.session_state.search_engine != "duckduckgo" else None

if st.session_state.search_engine:
    st.info(f"âœ“ {st.session_state.search_engine.capitalize()} ê²€ìƒ‰ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    search_results = None
    search_error = None
    
    if st.session_state.search_engine == "tavily":
        with st.spinner("Tavilyë¡œ ê²€ìƒ‰ ì¤‘..."):
            search_results, search_error = search_tavily(prompt)
    elif st.session_state.search_engine == "duckduckgo":
        with st.spinner("DuckDuckGoë¡œ ê²€ìƒ‰ ì¤‘..."):
            search_results, search_error = search_duckduckgo(prompt)
    
    current_conv["messages"].append(HumanMessage(content=prompt))
    user_msg_idx = len(current_conv["messages"]) - 1
    
    with st.chat_message("user"):
        st.markdown(prompt)
    
    if search_error:
        st.error(search_error)
        messages_with_search = current_conv["messages"].copy()
    elif search_results:
        current_conv["search_results"][user_msg_idx] = search_results
        
        with st.expander("ğŸ” ê²€ìƒ‰ ê²°ê³¼ ë³´ê¸°", expanded=False):
            st.markdown(search_results)
        
        augmented_prompt = f"{prompt}\n\n{search_results}\n\nìœ„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”."
        messages_with_search = current_conv["messages"][:-1] + [HumanMessage(content=augmented_prompt)]
    else:
        messages_with_search = current_conv["messages"].copy()
    
    if current_conv.get("system_prompt"):
        messages_with_system = [SystemMessage(content=current_conv["system_prompt"])] + messages_with_search
    else:
        messages_with_system = messages_with_search
    
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        for chunk in st.session_state.llm.stream(messages_with_system):
            full_response += chunk.content
            message_placeholder.markdown(full_response + "â–Œ")
        
        message_placeholder.markdown(full_response)
    
    current_conv["messages"].append(AIMessage(content=full_response))
    st.rerun()

