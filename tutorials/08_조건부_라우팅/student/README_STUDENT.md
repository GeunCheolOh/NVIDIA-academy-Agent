# ğŸ§­ ì¡°ê±´ë¶€ ë¼ìš°íŒ… (Conditional Routing) - í•™ìƒìš©

LLMì„ Routerë¡œ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ë‹¤ë¥¸ ì²˜ë¦¬ ê²½ë¡œë¡œ ë¶„ê¸°í•˜ëŠ” ì§€ëŠ¥í˜• Agentë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.

## ğŸ¯ í•™ìŠµ ëª©í‘œ

1. **Router LLM**: LLMì„ ì˜ì‚¬ê²°ì •ìë¡œ í™œìš©
2. **ì¡°ê±´ë¶€ ì—£ì§€**: LangGraphì—ì„œ ë™ì  ê·¸ë˜í”„ íë¦„ ì œì–´
3. **ë‹¤ì¤‘ ê²½ë¡œ**: VectorDB, WebSearch, Direct LLM
4. **í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ**: ì—¬ëŸ¬ ë°ì´í„° ì†ŒìŠ¤ í†µí•©

## ğŸ“‚ íŒŒì¼ êµ¬ì¡°

```
student/
â”œâ”€â”€ setup_d2l.py              # D2L PDF ë‹¤ìš´ë¡œë“œ ë° ë²¡í„° ìŠ¤í† ì–´ (ë¹ˆì¹¸ 2ê°œ)
â”œâ”€â”€ rag_router_agent.py        # Router Agent (ë¹ˆì¹¸ 6ê°œ)
â”œâ”€â”€ app_router.py              # Streamlit UI (ë¹ˆì¹¸ 2ê°œ)
â”œâ”€â”€ README_STUDENT.md          # ì´ íŒŒì¼
â”œâ”€â”€ requirements.txt
â””â”€â”€ env.example
```

## ğŸš€ ì„¤ì • ë°©ë²•

### 1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ .env íŒŒì¼ì— ì¶”ê°€
OPENAI_API_KEY=your-api-key
TAVILY_API_KEY=your-tavily-key
```

### 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

### 3. D2L êµì¬ ì„¤ì •

```bash
python setup_d2l.py
```

ì´ ëª…ë ¹ì€:
- D2L PDF ë‹¤ìš´ë¡œë“œ (https://d2l.ai/d2l-en.pdf)
- ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶• (./chroma_db_d2l)
- ì•½ 5-10ë¶„ ì†Œìš”

### 4. ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰

```bash
streamlit run app_router.py
```

## âœï¸ ë¹ˆì¹¸ ì±„ìš°ê¸° ê°€ì´ë“œ

### setup_d2l.py (2ê°œ ë¹ˆì¹¸)

#### ë¹ˆì¹¸ 1: PDF ë‹¤ìš´ë¡œë“œ
```python
response = requests.get(url, stream=True)
response.raise_for_status()
```
**íŒíŠ¸**: `requests.get()`ìœ¼ë¡œ PDFë¥¼ ìŠ¤íŠ¸ë¦¬ë° ë‹¤ìš´ë¡œë“œ

#### ë¹ˆì¹¸ 2: ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
```python
vectorstore = Chroma.from_documents(
    documents=chunks,
    embedding=embeddings,
    persist_directory=chroma_path
)
```
**íŒíŠ¸**: `Chroma.from_documents()`ë¡œ ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•

### rag_router_agent.py (6ê°œ ë¹ˆì¹¸)

#### ë¹ˆì¹¸ 1: Router Node - LLM í˜¸ì¶œ ë° JSON íŒŒì‹±
```python
response = self.llm.invoke([SystemMessage(content=router_prompt)])
result = json.loads(response.content)

route = result.get("route", "direct")
reasoning = result.get("reasoning", "ê¸°ë³¸ ê²½ë¡œ ì„ íƒ")
```
**íŒíŠ¸**: LLMì—ê²Œ ë¼ìš°íŒ… ê²°ì •ì„ ìš”ì²­í•˜ê³  JSON ì‘ë‹µ íŒŒì‹±

#### ë¹ˆì¹¸ 2: VectorDB Node - ë¬¸ì„œ ê²€ìƒ‰
```python
docs = self.d2l_retriever.invoke(question)
```
**íŒíŠ¸**: D2L êµì¬ ê²€ìƒ‰ê¸°ë¡œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰

#### ë¹ˆì¹¸ 3: WebSearch Node - ì›¹ ê²€ìƒ‰
```python
search_results = self.tavily_tool.invoke(question)
```
**íŒíŠ¸**: Tavily APIë¡œ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰

#### ë¹ˆì¹¸ 4: Direct LLM Node - LLM ì§ì ‘ ì‘ë‹µ
```python
conversation = messages + [HumanMessage(content=question)]
response = self.llm.invoke(conversation)
```
**íŒíŠ¸**: ëŒ€í™” ì´ë ¥ì„ í¬í•¨í•˜ì—¬ LLMì— ì§ì ‘ ì§ˆë¬¸

#### ë¹ˆì¹¸ 5: Answer Node - ìµœì¢… ë‹µë³€ ìƒì„±
```python
response = self.llm.invoke([SystemMessage(content=answer_prompt)])
```
**íŒíŠ¸**: ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±

#### ë¹ˆì¹¸ 6: ë¼ìš°íŒ… í•¨ìˆ˜
```python
return state["route"]
```
**íŒíŠ¸**: router_nodeì—ì„œ ê²°ì •í•œ ê²½ë¡œ ë°˜í™˜

### app_router.py (2ê°œ ë¹ˆì¹¸)

#### ë¹ˆì¹¸ 1: Router Agent ì´ˆê¸°í™”
```python
if "router_agent" not in st.session_state:
    retriever = st.session_state.vectorstore.as_retriever(
        search_kwargs={"k": 3}
    )
    st.session_state.router_agent = RouterAgent(
        d2l_retriever=retriever,
        api_key=os.getenv("OPENAI_API_KEY"),
        tavily_api_key=os.getenv("TAVILY_API_KEY")
    )
```
**íŒíŠ¸**: D2L ê²€ìƒ‰ê¸°ì™€ API í‚¤ë¡œ RouterAgent ìƒì„±

#### ë¹ˆì¹¸ 2: Router Agent í˜¸ì¶œ
```python
result = st.session_state.router_agent.invoke(
    question=prompt,
    chat_history=chat_history
)
```
**íŒíŠ¸**: ì§ˆë¬¸ê³¼ ëŒ€í™” ì´ë ¥ì„ ì „ë‹¬í•˜ì—¬ Agent ì‹¤í–‰

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë°©ë²•

### 1. ëª¨ë“ˆë³„ í…ŒìŠ¤íŠ¸

```bash
# Router Agent í…ŒìŠ¤íŠ¸
python3 -c "from rag_router_agent import RouterAgent; print('âœ… OK')"
```

### 2. ì „ì²´ ì•± ì‹¤í–‰

```bash
streamlit run app_router.py
```

### 3. ê²½ë¡œë³„ í…ŒìŠ¤íŠ¸

**VectorDB ê²½ë¡œ** (AI/ML ì§ˆë¬¸):
- "ë”¥ëŸ¬ë‹ì—ì„œ backpropagationì´ë€?"
- "CNNì˜ êµ¬ì¡°ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”"

**WebSearch ê²½ë¡œ** (ìµœì‹  ì •ë³´):
- "2024ë…„ ë…¸ë²¨ìƒ ìˆ˜ìƒìëŠ”?"
- "ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ?"

**Direct LLM ê²½ë¡œ** (ì¼ë°˜ ëŒ€í™”):
- "ì•ˆë…•í•˜ì„¸ìš”!"
- "Python ì½”ë“œ ì‘ì„±í•´ì¤˜"

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

```
ì‚¬ìš©ì ì§ˆë¬¸
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Router Node       â”‚
â”‚   (LLMì´ ê²½ë¡œ ê²°ì •) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“    â†“    â†“
â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”
â”‚Vec â”‚ â”‚Web â”‚ â”‚Direâ”‚
â”‚torDâ”‚ â”‚Searâ”‚ â”‚ct  â”‚
â”‚B   â”‚ â”‚ch  â”‚ â”‚LLM â”‚
â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜
    â†“    â†“      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Answer Node       â”‚
â”‚   (ìµœì¢… ë‹µë³€ ìƒì„±)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] setup_d2l.pyì˜ 2ê°œ ë¹ˆì¹¸ ì™„ì„±
- [ ] rag_router_agent.pyì˜ 6ê°œ ë¹ˆì¹¸ ì™„ì„±
- [ ] app_router.pyì˜ 2ê°œ ë¹ˆì¹¸ ì™„ì„±
- [ ] D2L ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶• ì™„ë£Œ
- [ ] ëª¨ë“ˆë³„ import í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] VectorDB ê²½ë¡œ í…ŒìŠ¤íŠ¸ ì„±ê³µ
- [ ] WebSearch ê²½ë¡œ í…ŒìŠ¤íŠ¸ ì„±ê³µ
- [ ] Direct LLM ê²½ë¡œ í…ŒìŠ¤íŠ¸ ì„±ê³µ
- [ ] ë¼ìš°íŒ… ì •ë³´ ì‹œê°í™” í™•ì¸

## ğŸ’¡ ë””ë²„ê¹… íŒ

### Router ì˜¤ë¥˜
```
âš ï¸ Router ì˜¤ë¥˜: ..., ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
```
- JSON íŒŒì‹± ì‹¤íŒ¨ â†’ LLM ì‘ë‹µ í™•ì¸
- ë¼ìš°íŒ… ë¡œì§ ê²€ì¦

### VectorDB ê²€ìƒ‰ ì‹¤íŒ¨
```
âŒ VectorDB ê²€ìƒ‰ ì‹¤íŒ¨: ...
```
- D2L ë²¡í„° ìŠ¤í† ì–´ í™•ì¸ (`setup_d2l.py` ì‹¤í–‰)
- retriever ì´ˆê¸°í™” í™•ì¸

### WebSearch ì˜¤ë¥˜
```
âŒ ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: ...
```
- Tavily API í‚¤ í™•ì¸
- ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸

## ğŸ“ í•™ìŠµ í¬ì¸íŠ¸

### LLM as Router

**ê°œë…**: LLMì„ ì˜ì‚¬ê²°ì • ì—”ì§„ìœ¼ë¡œ í™œìš©

```python
# LLMì—ê²Œ ì§ˆë¬¸ ìœ í˜• ë¶„ì„ ìš”ì²­
router_prompt = """
ì§ˆë¬¸: {question}

ì„ íƒì§€:
1. vectordb: AI/ML ì§ˆë¬¸ â†’ D2L êµì¬
2. websearch: ìµœì‹  ì •ë³´ â†’ ì›¹ ê²€ìƒ‰
3. direct: ì¼ë°˜ ëŒ€í™” â†’ LLM ì§ì ‘

JSON ì‘ë‹µ: {"route": "...", "reasoning": "..."}
"""

response = llm.invoke([SystemMessage(content=router_prompt)])
result = json.loads(response.content)
```

### ì¡°ê±´ë¶€ ì—£ì§€ (Conditional Edges)

**ê°œë…**: ìƒíƒœì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œë¥¼ ë™ì ìœ¼ë¡œ ê²°ì •

```python
workflow.add_conditional_edges(
    "router",
    route_question,  # ë¼ìš°íŒ… í•¨ìˆ˜
    {
        "vectordb": "vectordb",    # routeê°€ "vectordb"ë©´ vectordb ë…¸ë“œë¡œ
        "websearch": "websearch",  # routeê°€ "websearch"ë©´ websearch ë…¸ë“œë¡œ
        "direct": "direct_llm"     # routeê°€ "direct"ë©´ direct_llm ë…¸ë“œë¡œ
    }
)
```

### í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ

**ì¥ì **:
- ì •í™•ì„±: ì „ë¬¸ ì§€ì‹ì€ VectorDBì—ì„œ
- ìµœì‹ ì„±: ì‹¤ì‹œê°„ ì •ë³´ëŠ” WebSearchì—ì„œ
- ìœ ì—°ì„±: ì¼ë°˜ ì§ˆë¬¸ì€ LLM ì§ì ‘ ì²˜ë¦¬

**vs ë‹¨ì¼ ê²½ë¡œ**:
| í•­ëª© | í•˜ì´ë¸Œë¦¬ë“œ | ë‹¨ì¼ ê²½ë¡œ |
|------|-----------|----------|
| ì •í™•ë„ | ë†’ìŒ | ë³´í†µ |
| ë¹„ìš© | ìµœì í™” | ë†’ìŒ |
| ì†ë„ | ë¹ ë¦„ | ëŠë¦¼ |
| ìœ ì—°ì„± | ë†’ìŒ | ë‚®ìŒ |

## ğŸ”— ì°¸ê³  ìë£Œ

- **ì™„ì„± ì½”ë“œ**: `../complete/` í´ë”
- **ë ˆí¼ëŸ°ìŠ¤**: `reference/5_1_3_LangGraph_RAG_Agent.ipynb`
- **LangGraph ë¬¸ì„œ**: https://langchain-ai.github.io/langgraph/

## ğŸ“ ë„ì›€ì´ í•„ìš”í•˜ë©´

1. ì™„ì„± ì½”ë“œì™€ ë¹„êµ (`../complete/` í´ë”)
2. ë ˆí¼ëŸ°ìŠ¤ ë…¸íŠ¸ë¶ ì°¸ê³ 
3. ì£¼ì„ì˜ íŒíŠ¸ í™•ì¸

í™”ì´íŒ…! ğŸš€

