{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph 기반 검색 에이전트\n",
    "\n",
    "VectorDB와 웹 검색을 결합한 ReAct 방식의 하이브리드 검색 에이전트입니다.\n",
    "\n",
    "## 주요 기능\n",
    "1. ReAct 패턴 (Thought-Action-Observation)\n",
    "2. 검색 결과 평가 및 재시도\n",
    "3. 하이브리드 검색 (VectorDB + 웹)\n",
    "4. 대화 기록 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-openai langchain-community langgraph chromadb pymupdf tavily-python langgraph-checkpoint-sqlite -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "    os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')\n",
    "    print(\"Colab Secrets에서 API 키를 불러왔습니다.\")\n",
    "\n",
    "except (ImportError, KeyError):\n",
    "    openai_key = getpass.getpass(\"OpenAI API 키: \")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
    "    tavily_key = getpass.getpass(\"Tavily API 키: \")\n",
    "    os.environ[\"TAVILY_API_KEY\"] = tavily_key\n",
    "    print(\"API 키가 입력되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import TypedDict, Annotated, List\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PDF 다운로드 및 VectorDB 검색기 도구와 웹검색 도구 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pdf_path = \"d2l-en.pdf\"\n",
    "url = \"https://d2l.ai/d2l-en.pdf\"\n",
    "\n",
    "if not Path(pdf_path).exists():\n",
    "    print(\"PDF 다운로드 중...\")\n",
    "    !curl -L -o $pdf_path $url\n",
    "    print(\"다운로드 완료\")\n",
    "else:\n",
    "    print(f\"PDF 파일 존재: {pdf_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_db_path = \"./chroma_db_d2l\"\n",
    "\n",
    "if Path(chroma_db_path).exists():\n",
    "    print(\"기존 DB 로드...\")\n",
    "    vectorstore = Chroma(persist_directory=chroma_db_path, embedding_function=embeddings)\n",
    "else:\n",
    "    print(\"새 DB 생성...\")\n",
    "    loader = PyMuPDFLoader(pdf_path)\n",
    "    documents = loader.load()[:100]\n",
    "    print(f\"{len(documents)} 페이지 로드\")\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = splitter.split_documents(documents)\n",
    "    print(f\"{len(chunks)}개 청크 생성\")\n",
    "\n",
    "    print(\"임베딩 생성 중...\")\n",
    "    vectorstore = Chroma.from_documents(chunks, embeddings, persist_directory=chroma_db_path)\n",
    "    print(\"완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "web_search_tool = TavilySearchResults(max_results=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. State 및 노드 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[List, operator.add]\n",
    "    question: str\n",
    "    current_query: str\n",
    "    search_method: str\n",
    "    search_results: str\n",
    "    is_relevant: bool\n",
    "    iteration: int\n",
    "    final_answer: str\n",
    "\n",
    "def format_history(messages: List[BaseMessage]) -> str:\n",
    "    if not messages:\n",
    "        return \"\"\n",
    "    history = \"\\n이전 대화:\\n\"\n",
    "    for msg in messages[-6:]:\n",
    "        role = \"사용자\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "        history += f\"{role}: {msg.content[:200]}...\\n\"\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thought_node(state: AgentState):\n",
    "    print(\"\\n[Thought] 검색 전략 수립...\")\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    iteration = state.get(\"iteration\", 0)\n",
    "    messages = state.get(\"messages\", [])\n",
    "    \n",
    "    context = format_history(messages)\n",
    "    if iteration > 0:\n",
    "        context += f\"\\n이전 시도 실패, 다시 시도 필요\\n\"\n",
    "    \n",
    "    prompt = f\"{context}\\n질문: {question}\\n\\n검색 방법 선택 (vectordb: 딥러닝 교과서, websearch: 웹)\\nJSON으로 답변: {{\\\"search_method\\\": \\\"vectordb/websearch\\\", \\\"query\\\": \\\"검색어\\\", \\\"reasoning\\\": \\\"이유\\\"}}\"\n",
    "    \n",
    "    response = llm.invoke([SystemMessage(content=prompt)])\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(response.content)\n",
    "        method = result.get(\"search_method\", \"websearch\")\n",
    "        query = result.get(\"query\", question)\n",
    "        print(f\"방법: {method}, 쿼리: {query}\")\n",
    "        return {\"search_method\": method, \"current_query\": query, \"iteration\": iteration + 1}\n",
    "    except:\n",
    "        print(\"파싱 실패, 기본값 사용\")\n",
    "        return {\"search_method\": \"websearch\", \"current_query\": question, \"iteration\": iteration + 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_node(state: AgentState):\n",
    "    print(\"\\n[Action] 검색 수행...\")\n",
    "    \n",
    "    method = state[\"search_method\"]\n",
    "    query = state[\"current_query\"]\n",
    "    \n",
    "    if method == \"vectordb\":\n",
    "        print(f\"  VectorDB: '{query}'\")\n",
    "        docs = vectordb_retriever.invoke(query)\n",
    "        results = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "        print(f\"{len(docs)}개 문서 검색\")\n",
    "    else:\n",
    "        print(f\"  웹검색: '{query}'\")\n",
    "        search_results = web_search_tool.invoke(query)\n",
    "        results = \"\\n\\n\".join([f\"[{r.get('title')}]\\n{r.get('content')}\" for r in search_results])\n",
    "        print(\"검색 완료\")\n",
    "    \n",
    "    return {\"search_results\": results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observation_node(state: AgentState):\n",
    "    print(\"\\n[Observation] 결과 평가...\")\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    results = state[\"search_results\"]\n",
    "    iteration = state.get(\"iteration\", 0)\n",
    "    \n",
    "    eval_prompt = f\"\"\"검색 결과가 질문에 답할 수 있는지 평가:\n",
    "질문: {question}\n",
    "검색 결과: {results[:500]}...\n",
    "\n",
    "JSON으로 답변: {{\\\"is_relevant\\\": true/false, \\\"reason\\\": \\\"이유\\\", \\\"suggestion\\\": \\\"제안\\\"}}\"\"\"\n",
    "    \n",
    "    eval_response = llm.invoke([SystemMessage(content=eval_prompt)])\n",
    "    \n",
    "    try:\n",
    "        eval_result = json.loads(eval_response.content)\n",
    "        is_relevant = eval_result.get(\"is_relevant\", False)\n",
    "        print(f\"평가: {'관련 있음' if is_relevant else '관련 없음'}\")\n",
    "        \n",
    "        if not is_relevant and iteration < MAX_ITERATIONS:\n",
    "            print(f\"재시도 ({iteration}/{MAX_ITERATIONS})\")\n",
    "            return {\"is_relevant\": False}\n",
    "        \n",
    "        print(\"답변 생성...\")\n",
    "        messages = state.get(\"messages\", [])\n",
    "        answer_prompt = f\"{format_history(messages)}\\n질문: {question}\\n검색 결과: {results}\\n\\n위 결과로 답변하세요.\"\n",
    "        response = llm.invoke([SystemMessage(content=answer_prompt)])\n",
    "        \n",
    "        return {\n",
    "            \"is_relevant\": True,\n",
    "            \"final_answer\": response.content,\n",
    "            \"messages\": [HumanMessage(content=question), AIMessage(content=response.content)]\n",
    "        }\n",
    "    except:\n",
    "        return {\"is_relevant\": True, \"final_answer\": \"오류 발생\", \"messages\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 그래프 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITERATIONS = 5\n",
    "conn = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
    "memory = SqliteSaver(conn=conn)\n",
    "\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    is_relevant = state.get(\"is_relevant\", False)\n",
    "    iteration = state.get(\"iteration\", 0)\n",
    "    return \"end\" if (is_relevant or iteration >= MAX_ITERATIONS) else \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"thought\", thought_node)\n",
    "workflow.add_node(\"action\", action_node)\n",
    "workflow.add_node(\"observation\", observation_node)\n",
    "\n",
    "workflow.set_entry_point(\"thought\")\n",
    "workflow.add_edge(\"thought\", \"action\")\n",
    "workflow.add_edge(\"action\", \"observation\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"observation\",\n",
    "    should_continue,\n",
    "    {\"continue\": \"thought\", \"end\": END}\n",
    ")\n",
    "\n",
    "search_agent = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 실행 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(question: str, thread_id: str = \"default\", agent: StateGraph = search_agent):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"질문: {question}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    try:\n",
    "        current_state = agent.get_state(config)\n",
    "        existing_messages = current_state.values.get(\"messages\", []) if current_state.values else []\n",
    "    except:\n",
    "        existing_messages = []\n",
    "    \n",
    "    initial_state = {\n",
    "        \"question\": question,\n",
    "        \"current_query\": question,\n",
    "        \"messages\": existing_messages,\n",
    "        \"search_method\": \"\",\n",
    "        \"search_results\": \"\",\n",
    "        \"is_relevant\": False,\n",
    "        \"iteration\": 0,\n",
    "        \"final_answer\": \"\"\n",
    "    }\n",
    "    \n",
    "    result = agent.invoke(initial_state, config=config)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"최종 답변:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(result[\"final_answer\"])\n",
    "    print(f\"\\n총 반복: {result['iteration']}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 1: VectorDB 검색\n",
    "result1 = run_agent(\"경사 하강법(gradient descent)이란 무엇인가요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 2: 웹 검색\n",
    "result2 = run_agent(\"2025년 노벨상은 누가 수상했나요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 3: 대화 컨텍스트 유지\n",
    "result3 = run_agent(\"activation function이란?\", thread_id=\"test\")\n",
    "result4 = run_agent(\"그것의 종류는?\", thread_id=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
